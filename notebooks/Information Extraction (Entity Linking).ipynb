{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd32b26c-3707-476f-be11-bc4e0bf657ce",
   "metadata": {},
   "source": [
    "<img src=\"data/images/lecture-notebook-header.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d943c-7bdf-44a9-bb8a-d01690e101b0",
   "metadata": {},
   "source": [
    "# Entity Linking\n",
    "\n",
    "Entity linking is a natural language processing (NLP) technique that involves identifying and linking named entities in a given text to a knowledge base or database of entities. In NLP, named entities refer to specific entities that are referred to by name, such as people, organizations, places, and products. Entity linking involves disambiguating these named entities and identifying which specific entity they refer to.\n",
    "\n",
    "For example, consider the sentence \"Steve Jobs was the CEO of Apple.\" In this sentence, \"Steve Jobs\" and \"Apple\" are named entities. Entity linking would involve identifying that \"Steve Jobs\" refers to the person Steve Jobs and that \"Apple\" refers to the company Apple Inc. Entity linking is important in many NLP tasks, such as information retrieval, text classification, and question answering. By linking entities to a knowledge base, it enables machines to better understand the meaning of text and answer questions more accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e4d80-338c-4636-baac-3650aecf4a57",
   "metadata": {},
   "source": [
    "## Setting up the Notebook\n",
    "\n",
    "In this notebook, we use [DBpedia Spotlight](https://www.dbpedia-spotlight.org/). DBpedia Spotlight is an open-source tool for entity linking, which is a natural language processing (NLP) task that involves identifying and linking named entities in text to a knowledge base or database of entities. DBpedia Spotlight uses the DBpedia knowledge base, which is a structured database that extracts information from Wikipedia. DBpedia Spotlight works by analyzing text and identifying named entities such as people, organizations, and locations. It then links these entities to DBpedia, a knowledge base derived from the information in Wikipedia, allowing the entities to be identified and contextualized.\n",
    "\n",
    "DBpedia Spotlight can be used in a variety of NLP applications, such as information retrieval, text classification, and question answering. It is available as a RESTful web service and can be accessed through various programming languages, including Java, Python, and Ruby. It is designed to be highly scalable and efficient, making it suitable for large-scale applications. It also allows for customization and configuration, enabling users to adapt the tool to their specific needs.\n",
    "\n",
    "Conveniently, there exists [DBpedia Spotlight for SpaCy](https://spacy.io/universe/project/spacy-dbpedia-spotlight) to extend the analysis pipeline of spaCy to integrate DBpedia Spotlight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2103c6-63f3-43a8-972f-8e9778a958ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_dbpedia_spotlight.entity_linker.EntityLinker at 0x7f95e0221b70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import spacy_dbpedia_spotlight\n",
    "import requests, json\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "#nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe('dbpedia_spotlight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690768e-4c6d-4290-bac7-8299658ae6c3",
   "metadata": {},
   "source": [
    "## Running some Examples\n",
    "\n",
    "The code cell below contains some of the example sentences that we saw throughout the lecture. Since DBpedia Spotlight is not integrated into the spaCy pipeline, we can just analyze the sentences as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0183e74-481e-4571-8490-b5f212f50bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Elon Musk bought Twitter, headquartered in  San Francisco, in October 2022 for the amount of $44 Billion to avoid trial.\"\n",
    "text = \"Musk bought Twitter, headquartered in  San Francisco, in October 2022 for the amount of $44 Billion to avoid trial.\"\n",
    "#text = \"Washington was born into slavery on a farm of James Burroughs.\"\n",
    "#text = \"Bob arrived in Washington for what may well be his last state visit.\"\n",
    "#text = \"The Washington had proved to be a leaky ship.\"\n",
    "#text = \"Leonhard Euler was born in Basel.\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff2cd7-6481-499f-8d6f-5c84e2c20072",
   "metadata": {},
   "source": [
    "Two things you should notice:\n",
    "\n",
    "* The analysis now takes noticeably longer. This is simply because we need to call the DBpedia spotlight API to access the DBpedia knowledge graph\n",
    "\n",
    "* The results are not perfect. For example, when using \"Elon Musk\" the correct entity will be linked; it fails if it only says \"Musk\"\n",
    "\n",
    "We can also visualize the results using the [spaCy visualizers](https://spacy.io/usage/visualizers). In fact, we use the same approach as for NER but note how the output is not different and includes the links to the corresponding DBpedia pages (i.e., the unique URLs to the concepts in the knowledge base).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ab248-57d1-4049-bd4e-96742ba066e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Musk bought \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DBPEDIA_ENT\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">http://dbpedia.org/resource/Twitter</a>\n",
       "</span>\n",
       "</mark>\n",
       ", headquartered in  \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DBPEDIA_ENT\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">http://dbpedia.org/resource/San_Francisco</a>\n",
       "</span>\n",
       "</mark>\n",
       ", in October 2022 for the amount of $44 Billion to avoid trial.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcc172-0f8a-4f23-a6f2-83d320da1326",
   "metadata": {},
   "source": [
    "## Doing it \"Manually\"\n",
    "\n",
    "While using spaCy with the DBpedia extensions is convenient, it also hides all of the logic. This means we have to rely on how well DBpedia Spotlight works. However, alternatively, we can also directly use knowledge base APIs to search for candidates and rank/filter/select/etc. the best candidate ourselves. To illustrate this, we can use Wikidata. This is a free and open knowledge graph maintained by the Wikimedia Foundation. It provides a structured data model that enables the creation, editing, and linking of data across a wide range of domains and disciplines, such as history, science, culture, and geography. Wikidata contains data about entities such as people, places, organizations, events, and concepts, and it is designed to be machine-readable and interlinked with other knowledge resources on the web. Wikidata's data is contributed and maintained by a community of editors and volunteers from around the world, and it is used by a wide range of applications, such as search engines, recommender systems, and natural language processing tools. The structured data model used by Wikidata is based on Semantic Web technologies such as RDF and OWL, and it is designed to support the integration and interoperability of data from different sources and domains.\n",
    "\n",
    "The method `call_wikidata_api()` implements a very basic search API call that takes a search term as input and returns all matching results as a JSON document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea74741-b124-46f4-9b34-8fa8c91add27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_wikidata_api(search, topk=5):\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={search}&language=en&format=json\"\n",
    "        data = requests.get(url).json()\n",
    "        return data['search'][:topk]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3941b4-5390-4e08-994b-20382c79d1aa",
   "metadata": {},
   "source": [
    "Let's call the method with the search term \"Euler\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e303ddb-bfa4-49fd-a6f2-672792cfdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate in call_wikidata_api(\"Euler\"):\n",
    "    print(\"[{}] {} ({})\".format(candidate['id'], candidate['label'], candidate['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333bde7-82c2-461c-bf2e-f846778c9cdd",
   "metadata": {},
   "source": [
    "Presumably, the API performs some sorting of the results based on some criteria reflecting the entity's popularity in the knowledge base. However, since we generally get a whole list of candidates we can perform any kind of additional candidate selection to find the best-matching entity for our candidate. This is beyond the scope of this notebook though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc642b64-f60c-45aa-a0f7-3977b6ebc8a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf0d09-d913-45c6-86dd-c272209bdd6d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Entity linking is a process in natural language processing that connects textual mentions of entities, such as names of people, places, or things, to their corresponding entries in a knowledge base or database. The goal is to disambiguate ambiguous references in text by identifying the specific entity being referred to. It involves recognizing the entity in the text and then linking it to a unique identifier in a knowledge base, enabling systems to better understand and process information.\n",
    "\n",
    "Practically, entity linking has numerous applications across various fields. In information retrieval and web search, it improves search accuracy by providing relevant information about entities mentioned in queries or documents. In content recommendation systems, it enhances personalization by understanding user interests through linked entities. Moreover, in data integration and knowledge graph construction, entity linking helps in connecting disparate datasets and building comprehensive knowledge graphs that facilitate better data analysis and knowledge representation.\n",
    "\n",
    "Furthermore, entity linking plays a crucial role in natural language understanding tasks like question answering, information extraction, and sentiment analysis. By linking entities to rich sources of information in knowledge bases like DBpedia, Wikidata, or Freebase, systems can augment their understanding of text, enabling more sophisticated and context-aware analysis and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba650466-17c8-49a2-8576-50bfc8e180a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5246]",
   "language": "python",
   "name": "conda-env-cs5246-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
